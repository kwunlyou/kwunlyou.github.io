[{"authors":["admin"],"categories":null,"content":"I am currently a data scientist at IHS Markit. I analyze data from company databases to drive optimization and improvement of product development and business strategies for a variety of industries including financial services, economics, energy, maritime, etc. From 2013 to 2016, I was a research associate at University College London (UCL). I was building a big data platform which was able to process massive amounts of geospatial data. From 2010 to 2013, I was a PhD researcher at the ALICE team of INRIA (French Institute for Research in Computer Science and Automation). I carried out extensive research which proposed novel methods to process 3D data acquired by multiple cameras. I received my doctorate in computer science from Institut National Polytechnique de Lorraine.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"https://kun-liu.com/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"author","summary":"I am currently a data scientist at IHS Markit. I analyze data from company databases to drive optimization and improvement of product development and business strategies for a variety of industries including financial services, economics, energy, maritime, etc. From 2013 to 2016, I was a research associate at University College London (UCL). I was building a big data platform which was able to process massive amounts of geospatial data. From 2010 to 2013, I was a PhD researcher at the ALICE team of INRIA (French Institute for Research in Computer Science and Automation).","tags":null,"title":"Kun Liu","type":"author"},{"authors":[],"categories":["Numerical Computing"],"content":" 1. Problem statement 17/12/21 11:11:56 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS 17/12/21 11:11:56 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS  The warning messages are often displayed when you use MLlib in Apache Spark. It means native BLAS implementations are not rightly installed or configured for your Apache Spark. A pure Java implementation is used which could harm the performance. See [1] for more information.\nThe official Spark document [2] has an explanation about the warning message\n MLlib uses the linear algebra package Breeze, which depends on netlib-java for optimised numerical processing. If native libraries are not available at runtime, you will see a warning message and a pure JVM implementation will be used instead. {: style=\u0026ldquo;font-size: 100%\u0026ldquo;}\n and\n Due to licensing issues with runtime proprietary binaries, we do not include netlib-javaâ€™s native proxies by default. {: style=\u0026ldquo;font-size: 100%\u0026ldquo;}\n 2. Solutions As stated in the official Spark document [2],\n To configure netlib-java / Breeze to use system optimised binaries, include com.github.fommil.netlib:all:1.1.2 (or build Spark with -Pnetlib-lgpl) as a dependency of your project {: style=\u0026ldquo;font-size: 100%\u0026ldquo;}\n there are two kinds of solutions\n rebuild Apache Spark configure your project  The first one is almost impossible in some scenario such as Amazon EMR. This post focus on the second solution instead.\n2.1 Aside Most of the linear algebra related functions in Spark MLlib are based on Breeze which is a numerical processing library for Scala, while some of them are directly based on the low level library netlib-java which is also used by Breeze. In addition, Spark MLlib has some non-BLAS in-house implementations as well.\nIn netlib-java, the implementations of BLAS/LAPACK are provided by\n \u0026ldquo;F2J to ensure full portability on the JVM\u0026rdquo; \u0026ldquo;self-contained native builds using the reference Fortran from netlib.org\u0026ldquo; \u0026ldquo;delegating builds that use machine optimised system libraries\u0026rdquo;  The relation is illustrated as the figure. In this post, we are trying to configure and use system-provided BLAS (in green).\n2.2 Steps Step 1: Make sure a native BLAS/LAPACK implementation is installed such as ATLAS, Intel MKL, and OpenBLAS. OpenBLAS generally has an excellent performance among free implementations. If you work on macOS, its vecLib contains Apple\u0026rsquo;s highly tuned implementation of BLAS/LAPACK.\nStep 2: As sugguested in the official Spark documeny [2], include com.github.fommil.netlib:all:1.1.2 in your project to use system optimized binaries.\nHowever, this is not enough. If you use sbt, you have to use sbt-assembly to generate a fat JAR for your project in order to include netlib-java.\nStep 3: Add your generated fat JAR to spark.driver.extraClassPath and spark.executor.extraClassPath in spark-default.conf. Do not use --driver-class-path or --jars when you spark-submit your jobs, it does not work (I also want to know why).\nFor pyspark jobs, you only need to do the same configuration in order to use native BLAS.\nNOTE: frequently changing spark-default.conf is not convenient. Instead, you can prepare two JARs, one is for your project and one is for netlib-java.\n3. Others 3.1 Amazon Linux As some people said [3], the BLAS/LAPACK installed in Amazon Linux does not perform well. We can install OpenBLAS instead. Here is a bash script to install OpenBLAS in Amazon Linux:\n#!/bin/bash set -e sudo yum install -y git git clone https://github.com/xianyi/OpenBlas.git cd OpenBlas/ make clean make -j sudo mkdir /usr/lib64/OpenBLAS sudo chmod o+w,g+w /usr/lib64/OpenBLAS/ make PREFIX=/usr/lib64/OpenBLAS install sudo rm /etc/ld.so.conf.d/atlas-x86_64.conf sudo ldconfig sudo ln -sf /usr/lib64/OpenBLAS/lib/libopenblas.so /usr/lib64/libblas.so sudo ln -sf /usr/lib64/OpenBLAS/lib/libopenblas.so /usr/lib64/libblas.so.3 sudo ln -sf /usr/lib64/OpenBLAS/lib/libopenblas.so /usr/lib64/libblas.so.3.5 sudo ln -sf /usr/lib64/OpenBLAS/lib/libopenblas.so /usr/lib64/libblas.so.3.5.0 sudo ln -sf /usr/lib64/OpenBLAS/lib/libopenblas.so /usr/lib64/liblapack.so sudo ln -sf /usr/lib64/OpenBLAS/lib/libopenblas.so /usr/lib64/liblapack.so.3 sudo ln -sf /usr/lib64/OpenBLAS/lib/libopenblas.so /usr/lib64/liblapack.so.3.5 sudo ln -sf /usr/lib64/OpenBLAS/lib/libopenblas.so /usr/lib64/liblapack.so.3.5.0  3.2 The multi-thread issue As presented in the issue Spark-21305, BLAS with multi-thread support can cause worse performance because it conflicts with Spark executors. Therefore, it is better to disable multi-thread.\n3.3 Paper [4] is a bit out of date but is still very worth to read. It gives lots of details about implementations in Spark and experimental results using different BLAS implementations.\n3.4 Motivation This post is originated from reading [3]. I found lots of related posts but they are either not complete or out of date. Thus, I decide to record all what I read during solving the problem. All comments are welcome.\nReferences: 1. Improving BLAS library performance for MLlib\n2. MLlib Guide\n3. A question in Stackoverflow\n4. Matrix Computations and Optimization in Apache Spark\n","date":1513810800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1513810800,"objectID":"75d682f9d5cef1b3349a495d935f0ec9","permalink":"https://kun-liu.com/2017/12/21/use-native-blas/lapack-in-apache-spark/","publishdate":"2017-12-21T00:00:00+01:00","relpermalink":"/2017/12/21/use-native-blas/lapack-in-apache-spark/","section":"post","summary":"The warning messages are often displayed when you use MLlib in Apache Spark. It means native BLAS implementations are not rightly installed or configured for your Apache Spark. A pure Java implementation is used which could harm the performance.","tags":["Apache Spark","BLAS","LAPACK","Breeze","netlib-java"],"title":"Use Native BLAS/LAPACK in Apache Spark","type":"post"},{"authors":[],"categories":["Machine Learning"],"content":" 1. Introduction In machine learning, imbalanced classes is very common in practice. However, no algorithm can deal with the issue directly and other auxiliary methods must be introduced explicitly to resolve the challenge. This short post aims to briefly cover related topics on imbalanced classes in machine learning.\n2. Methods  do nothing (if lucky enough) data-level:  decrease majority size: using clustering methods such as K-means Condensed Nearest Neighbours  Tomek\u0026rsquo;s links  increase minority size: synthesize new samples:  SMOTE (Synthetic Minority Over-sampling Technique) ADASYN (Adaptive Synthetic Sampling Approach for Imbalanced Learning)   algorithm-level:  class weights decision thresholds ensemble techniques boostrap aggregating (bagging) [code]  Pros: Good for reducing variance, robust to noise, void overfitting Cons: Can be worse if single estimator is bad (use boosting)  boosting (weak learners to a strong learner)  Adaptive Boosting (AdaBoost) Gradient Boosting  remove minority examples and switch to an anomaly detection problem Isolation-Based Anomaly Detection Efficient Anomaly Detection by Isolation Using Nearest Neighbour Ensemble  others:  All the Data and Still Not Enough Transfer learning    3. Evaluation metrics  Do not use accuracy, precision, recall, F1 score (hard cutoff on predicted probabilties); use ROC curve, PR curve, AUC PR curve is prefered than ROC curve  2015 - The Precision-Recall Plot Is More Informative than the ROC Plot When Evaluating Binary Classifiers on Imbalanced Datasets 2006 - The Relationship Between Precision-Recall and ROC Curves 2005 - An introduction to ROC analysis   4. Resources:  Podcast:  Data Sciece at Home: How to handle imbalanced datasets  Blog:  Learning from Imbalanced Classes Imbalanced Classes FAQ Handling Class Imbalance with R and Caret - Caveats when using the AUC [Part 1] [Part2]  Paper:  A Survey of Predictive Modelling under Imbalanced Distributions Class Imbalance, Redux Using Random Forest to Learn Imbalanced Data  Code:  sklearn class_weight in logistic regression sklearn.model_selection.StratifiedKFold sklearn.calibration.CalibratedClassifierCV imbalanced-learn The R package unbalanced    ","date":1511132400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1511132400,"objectID":"149d96f7797a0d0d7b39a8002a40818e","permalink":"https://kun-liu.com/2017/11/20/imbalanced-classes-in-machine-learning/","publishdate":"2017-11-20T00:00:00+01:00","relpermalink":"/2017/11/20/imbalanced-classes-in-machine-learning/","section":"post","summary":"In machine learning, imbalanced classes is very common in practice. However, no algorithm can deal with the issue directly and other auxiliary methods must be introduced explicitly to resolve the challenge. This short post aims to briefly cover related topics on imbalanced classes in machine learning.","tags":["Imbalanced Classes"],"title":"Imbalanced Classes in Machine Learning","type":"post"},{"authors":[],"categories":["Programming"],"content":" Name normalization Name normalization happens when using pip to install python package. Dash '-', underscore '_' and period '.'are conflated based on certain rules when pip searchs for packages.\nFind packages For example, we use the following command to install a package aaa.bbb_ccc.\npip install aaa.bbb_ccc  pip will search for the package aaa.bbb_ccc on PyPI. The \u0026ldquo;best\u0026rdquo; match for the requirements is selected (see pip guide and source code for details). Loosely speaking, the \u0026ldquo;best\u0026rdquo; match is the newest version of the package.\nMatching wheel names  The package name aaa.bbb_ccc is transformed to aaa-bbb-ccc by calling canonicalize_name(source code)   # extracted from pip source code _canonicalize_regex = re.compile(r\u0026quot;[-_.]+\u0026quot;) def canonicalize_name(name): return _canonicalize_regex.sub(\u0026quot;-\u0026quot;, name).lower()   The wheel name is transformed in the same way (source code)  Matching tarball names  aaa.bbb_ccc is converted to aaa.bbb-ccc by calling safe_name (source code)  # extracted from pip source code def safe_name(name): \u0026quot;\u0026quot;\u0026quot;Convert an arbitrary string to a standard distribution name Any runs of non-alphanumeric/. characters are replaced with a single '-'. \u0026quot;\u0026quot;\u0026quot; return re.sub('[^A-Za-z0-9.]+', '-', name)   '_' in the tarball name is replaced by '-' (source code)  Package name convention in PEP 8 PEP 8 doesn\u0026rsquo;t encourage a long and complicated package name.\n# extracted from PEP 8 Python packages should also have short, all-lowercase names, although the use of underscores is discouraged.  ","date":1507762800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1507762800,"objectID":"779989243230b650090d3909ed866310","permalink":"https://kun-liu.com/2017/10/12/package-name-normalization-for-pip-installing/","publishdate":"2017-10-12T00:00:00+01:00","relpermalink":"/2017/10/12/package-name-normalization-for-pip-installing/","section":"post","summary":"Name normalization happens when using pip to install python package. Dash, underscore and period are conflated based on certain rules when pip searchs for packages.","tags":["Python","Pip","Package Name"],"title":"Package Name Normalization for Pip Installing","type":"post"},{"authors":[],"categories":["DIY"],"content":" Materials:  Raspberry Pi Zero Raspberry Pi Zero camera adapter Raspberry Pi NoIR camera module V2 USB to microUSB OTG converter shim USB Wifi adapter for the Raspberry Pi SanDisk Ultra 16 GB Memory Card The official Raspberry Pi Zero case USB charger plug with USB to micro USB (originally for LG Nexus 5) Mini camera tripod  Raspberry Pi Zero Headless Setup:  Install the operating system Raspbian: Download the image RASPBIAN JESSIE LITE, and write the image to the SD card following the online instruction.\n Conifgure SSH access via USB: Modify config.txt and cmdline.txt respectively in the /boot/ dicrectory based on this guide. Note, SSH is disabled on the lastest Raspbian by default as stated in this security update. To enable SSH, we have to create a file named as ssh in the /boot/ directory.\n SSH to Raspberry Pi Zero Insert the SD card to Raspberry Pi Zero and connect it to your PC or laptop via the the USB cable. Note, the micro USB side must to be connected with the data port (not power port) of Raspberry Pi Zero. Type ssh pi@raspberrypi.local in your terminal to SSH to Raspberry Pi Zero, the default password is raspberry.\n Configure the WIFI Basically, /etc/network/interfaces and /etc/wpa_supplicant/wpa_supplicant.conf have to be modified. You can follow this article to finish the configuration.\n  Raspberry Pi Zero Camera Setup:  Enable the connection to the Raspberry Pi camera sudo raspi-conf, go to interfacing options, and enable the camera. Reboot the Raspberry Pi Zero. Install the python package picamera and type the command raspistill -o image.jpg to make sure everything works well.\n Intsall RPi-Cam-Web-Interface Follow the official document to install the package which provides a convenient web interface to manage and configure Pi camera. It also supports motion detection.\n  Done. Enjoy!\n","date":1482447600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1482447600,"objectID":"b3c8037ec43e826f1b3b64972ce47e63","permalink":"https://kun-liu.com/2016/12/23/raspberry-pi-zero-video-monitor/","publishdate":"2016-12-23T00:00:00+01:00","relpermalink":"/2016/12/23/raspberry-pi-zero-video-monitor/","section":"post","summary":"Materials:  Raspberry Pi Zero Raspberry Pi Zero camera adapter Raspberry Pi NoIR camera module V2 USB to microUSB OTG converter shim USB Wifi adapter for the Raspberry Pi SanDisk Ultra 16 GB Memory Card The official Raspberry Pi Zero case USB charger plug with USB to micro USB (originally for LG Nexus 5) Mini camera tripod  Raspberry Pi Zero Headless Setup:  Install the operating system Raspbian: Download the image RASPBIAN JESSIE LITE, and write the image to the SD card following the online instruction.","tags":["Raspberry Pi"],"title":"Raspberry Pi Zero Video Monitor","type":"post"},{"authors":[],"categories":["Numerical Computing"],"content":"Recently I have to accelerate my last code and most of time are spent on solving linear sparse systems. Since my coefficient matrix is a symmetric positive definite matrix (s.p.d.), I always use CHOLMOD . But its performance cannot reach my requirement, I tried to search another better solver. Then I tried backslash(\\) in MATLAB, the build-in preconditioned conjugate gradient (PCG) method in Eigen, PARDISO in intel MKL and PCG in intel MKL.\nThere is a comparison article (from Tim Davis) of CHOLMOD with PCG method [link]. The main idea is that CHOLMOD performs bettter than PCG in most cases. However, unfortunately from my experiments it seems that PCG is more suitable than direct solvers (CHOLMOD and MKL) in my case. PCG need less time than direct solvers (CHOLMOD and MKL) to get similar results in my problem. Here is a figure roughly showing my results:\nNOTE: x axis represents the size of the coefficient matrix and y axis represents the solving time.\nHowever, in my problem I have to solve lots of times linear sparse systems. It is not as fast as I want. Probably I have to improve the theory part to nail the problem now? Or is there another other better solvers? Je ne sais pas. :(\n","date":1343343600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1343343600,"objectID":"9f88fbebbf51f9a42f557c0652c13b5c","permalink":"https://kun-liu.com/2012/07/27/linear-sparse-solvers/","publishdate":"2012-07-27T00:00:00+01:00","relpermalink":"/2012/07/27/linear-sparse-solvers/","section":"post","summary":"Recently I have to accelerate my last code and most of time are spent on solving linear sparse systems. Since my coefficient matrix is a symmetric positive definite matrix (s.p.d.), I always use CHOLMOD. But its performance cannot reach my requirement, I tried to search another better solver.","tags":["CHOLMOD","Linear Sparse Solver","MATLAB","MKL","PCG"],"title":"Linear Sparse Solvers","type":"post"},{"authors":[],"categories":["Numerical Computing"],"content":"Download, compile and install gotoBLAS2 (NOTE: With new CPU, it may have errors when compiling. We can get solutions by searching the errors information online).\nDownload, compile and install SuiteSparse.\nJust follow the manual then everything should be OK. Here is a demo which uses CHOLMOD as linear sparse solver.\nDownload: CHOLMOD_Demo (Sorry, the link is dead.) ","date":1331766000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1331766000,"objectID":"c8411426598bfd0fafeaf0ace7266969","permalink":"https://kun-liu.com/2012/03/15/quick-start-with-suitesparse-for-linear-sparse-solver/","publishdate":"2012-03-15T00:00:00+01:00","relpermalink":"/2012/03/15/quick-start-with-suitesparse-for-linear-sparse-solver/","section":"post","summary":"Download, compile and install gotoBLAS2 (NOTE\u0026#58; With new CPU, it may have errors when compiling. We can get solutions by searching the errors information online).","tags":["Linear Sparse Solver"],"title":"Quick Start With Suitesparse for Linear Sparse Solver","type":"post"}]